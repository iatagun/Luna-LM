"""
Luna-LM Test Script
EÄŸitilmiÅŸ modeli (pretrained veya SFT) test etmek iÃ§in
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import torch

from luna.utils import load_model
from luna.generate import generate_text


# SFT Prompt Format
SYSTEM_PROMPT = "Senin adÄ±n Luna. AmacÄ±n insanlara yardÄ±mcÄ± olmak ve sorulara aÃ§Ä±k, anlaÅŸÄ±lÄ±r cevaplar vermektir. Emin olmadÄ±ÄŸÄ±n konularda bunu belirtir, uydurma bilgi eklemezsin. CevaplarÄ±nÄ± nazik, sade ve doÄŸal bir TÃ¼rkÃ§e ile yazarsÄ±n."


def format_sft_prompt(user_query):
    return f"<system>{SYSTEM_PROMPT}</system>\n<user>{user_query}</user>\n<assistant>"


def clean_sft_output(generated):
    """Tokenizer artifactlerini temizle ve asistan cevabÄ±nÄ± Ã§Ä±kar"""
    clean_gen = generated.replace("< assistant >", "<assistant>").replace("< / assistant >", "</assistant>")
    clean_gen = clean_gen.replace("< user >", "<user>").replace("< / user >", "</user>")
    clean_gen = clean_gen.replace("< system >", "<system>").replace("< / system >", "</system>")
    
    # En son aÃ§Ä±lan <assistant> taginden sonrasÄ±nÄ± al
    if "<assistant>" in clean_gen:
        answer = clean_gen.split("<assistant>")[-1]
    else:
        answer = clean_gen
        
    # Stop token kontrolÃ¼
    for stop_token in ["</assistant>", "<user>", "<system>"]:
        if stop_token in answer:
            answer = answer.split(stop_token)[0]
    
    # Gereksiz karakter temizliÄŸi
    answer = answer.strip()
    while answer and (answer[0] in ('>', ' ', '.')):
        answer = answer[1:].strip()
        
    return answer


def main():
    print("="*60)
    print("LUNA-LM TEST")
    print("="*60)
    
    # Device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")
    
    # Proje kÃ¶k dizini
    project_root = os.path.join(os.path.dirname(__file__), '..')
    
    # Model yÃ¼kle â€” Ã¶nce SFT modeline bak, yoksa checkpoint klasÃ¶rÃ¼ne
    sft_path = os.path.join(project_root, "luna_sft_finetuned.pt")
    pretrain_path = os.path.join(project_root, "luna_lm_checkpoints_20251218_121142")
    
    if os.path.exists(sft_path):
        checkpoint_path = sft_path
    elif os.path.exists(pretrain_path):
        checkpoint_path = pretrain_path
    else:
        print("âŒ Model bulunamadÄ±!")
        return
        
    print(f"\nğŸ“¦ Model Yolu: {checkpoint_path}")
    
    try:
        model, tokenizer, config = load_model(checkpoint_path, device)
    except Exception as e:
        print(f"\nâš ï¸ Model yÃ¼klenirken hata oluÅŸtu: {e}")
        return
    
    # Test prompts (SFT iÃ§in Soru FormatÄ±nda)
    print("\n" + "="*60)
    print("SFT FORMATLI METÄ°N ÃœRETÄ°MÄ° TESTÄ°")
    print("="*60)
    
    test_questions = [
        "GÃ¼neÅŸ hangi yÃ¶nden doÄŸar?",
        "AmpulÃ¼ kim buldu?",
        "Ä°stanbul'un Ã¶nemi nedir?",
        "Mutluluk nedir?",
        "Bana bir hikaye anlat.",
        "Kravat nasÄ±l baÄŸlanÄ±r?",
    ]
    
    for q in test_questions:
        print(f"\nâ“ Soru: '{q}'")
        print("-" * 40)
        
        full_prompt = format_sft_prompt(q)
        
        generated = generate_text(
            model, tokenizer, device,
            full_prompt, 
            max_new_tokens=100, 
            temperature=0.2,    
            top_k=40,
            repetition_penalty=1.2 
        )
        
        answer = clean_sft_output(generated)
        print(f"ğŸ¤– Luna: {answer}")

    # Ä°nteraktif mod
    print("\n" + "="*60)
    print("Ä°NTERAKTÄ°F SOHBET MODU (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q')")
    print("="*60)
    
    while True:
        user_input = input("\nSiz: ").strip()
        if user_input.lower() == 'q':
            print("GÃ¶rÃ¼ÅŸÃ¼rÃ¼z! ğŸ‘‹")
            break
        
        if not user_input:
            continue
        
        full_prompt = format_sft_prompt(user_input)
        
        generated = generate_text(
            model, tokenizer, device,
            full_prompt,
            max_new_tokens=150,
            temperature=0.7,
            top_k=50,
            repetition_penalty=1.2
        )
        
        answer = clean_sft_output(generated)
        print(f"Luna: {answer}")


if __name__ == "__main__":
    main()

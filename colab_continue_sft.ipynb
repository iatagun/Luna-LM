{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåô Luna-LM ‚Äî Continued SFT (InstrucTurca 1.5M)\n",
    "\n",
    "**Ba≈ülangƒ±√ß:** `sft_20260301_005948` checkpoint'inden devam\n",
    "**Veri:** InstrucTurca ‚Äî satƒ±r 1.000.001'den 2.500.000'e kadar (~1.5M √∂rnek)\n",
    "**Neden?:** ƒ∞lk SFT d√º≈ü√ºk LR (2e-5) ile iyi √ßalƒ±≈ütƒ±, ≈üimdi daha da a≈üaƒüƒ± ineceƒüiz (5e-6)\n",
    "**Beklenen S√ºre:** ~4-6 saat (H100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. GPU Doƒürula\n",
    "import torch\n",
    "print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "print(f'BF16 destekli: {torch.cuda.is_bf16_supported()}')\n",
    "assert torch.cuda.is_available(), '‚ùå GPU yok!'\n",
    "print('‚úÖ GPU hazƒ±r!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Google Drive Baƒüla\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "DRIVE_DIR = '/content/drive/MyDrive/LunaLM'\n",
    "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
    "print(f'‚úÖ Drive: {DRIVE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Repo G√ºncelle\n",
    "import sys, os\n",
    "if not os.path.exists('/content/Luna-LM'):\n",
    "    !git clone https://github.com/iatagun/Luna-LM.git /content/Luna-LM\n",
    "else:\n",
    "    !cd /content/Luna-LM && git pull\n",
    "\n",
    "sys.path.insert(0, '/content/Luna-LM')\n",
    "os.chdir('/content/Luna-LM')\n",
    "print('‚úÖ Repo hazƒ±r!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Baƒüƒ±mlƒ±lƒ±klar\n",
    "!pip install -q transformers datasets\n",
    "import transformers, datasets as ds_lib\n",
    "print(f'‚úÖ transformers {transformers.__version__}')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='Token indices sequence length')\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. √ñnceki SFT Checkpoint'ini Drive'dan Y√ºkle\n",
    "# ‚¨áÔ∏è BURAYA kendi checkpoint klas√∂r adƒ±nƒ± yaz!\n",
    "PREV_SFT_NAME = 'sft_20260301_005948'\n",
    "\n",
    "SFT_CHECKPOINT_DRIVE = f'{DRIVE_DIR}/{PREV_SFT_NAME}'\n",
    "SFT_CHECKPOINT_LOCAL = f'/content/Luna-LM/checkpoints/{PREV_SFT_NAME}'\n",
    "\n",
    "import shutil\n",
    "if not os.path.exists(SFT_CHECKPOINT_LOCAL):\n",
    "    if os.path.exists(SFT_CHECKPOINT_DRIVE):\n",
    "        print('Checkpoint kopyalanƒ±yor...')\n",
    "        shutil.copytree(SFT_CHECKPOINT_DRIVE, SFT_CHECKPOINT_LOCAL)\n",
    "    else:\n",
    "        print(f'‚ùå Checkpoint bulunamadƒ±: {SFT_CHECKPOINT_DRIVE}')\n",
    "        print('Drive klas√∂r√ºn√º kontrol edin!')\n",
    "\n",
    "if os.path.exists(SFT_CHECKPOINT_LOCAL):\n",
    "    files = os.listdir(SFT_CHECKPOINT_LOCAL)\n",
    "    print(f'‚úÖ Checkpoint: {SFT_CHECKPOINT_LOCAL}')\n",
    "    print(f'  Dosyalar: {files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. InstrucTurca ‚Äî Kalan 1.5M Veri ƒ∞ndir (offset=1.000.000)\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "SFT_PATH = '/content/Luna-LM/sft/sft_continued_dataset.jsonl'\n",
    "\n",
    "# Eƒüer daha √∂nce indirildiyse (Drive cache'inden kopyala)\n",
    "SFT_PATH_DRIVE = f'{DRIVE_DIR}/sft_continued_dataset.jsonl'\n",
    "\n",
    "if not os.path.exists(SFT_PATH):\n",
    "    if os.path.exists(SFT_PATH_DRIVE):\n",
    "        print('Dataset Drive\\'dan kopyalanƒ±yor...')\n",
    "        shutil.copy(SFT_PATH_DRIVE, SFT_PATH)\n",
    "    else:\n",
    "        print('InstrucTurca indiriliyor (1.5M satƒ±r, offset=1M)...')\n",
    "        ds = load_dataset('turkish-nlp-suite/InstrucTurca', split='train')\n",
    "        print(f'Dataset: {len(ds):,} satƒ±r')\n",
    "        \n",
    "        valid = 0\n",
    "        OFFSET = 1_000_000   # ƒ∞lk 1M zaten kullanƒ±ldƒ±\n",
    "        LIMIT  = 1_500_000   # 1.5M daha al\n",
    "        \n",
    "        with open(SFT_PATH, 'w', encoding='utf-8') as f:\n",
    "            for i, row in enumerate(ds):\n",
    "                if i < OFFSET:\n",
    "                    continue  # ƒ∞lk 1M'i atla\n",
    "                if valid >= LIMIT:\n",
    "                    break\n",
    "                \n",
    "                # Case-insensitive kolon e≈üleme\n",
    "                row_lower = {k.lower(): v for k, v in row.items()}\n",
    "                instruction = ''\n",
    "                output_text = ''\n",
    "                \n",
    "                for key in ['instruction', 'prompt', 'question', 'input']:\n",
    "                    if row_lower.get(key):\n",
    "                        instruction = str(row_lower[key]).strip()\n",
    "                        break\n",
    "                for key in ['output', 'response', 'assistant', 'answer']:\n",
    "                    if row_lower.get(key):\n",
    "                        output_text = str(row_lower[key]).strip()\n",
    "                        break\n",
    "                \n",
    "                if not instruction or not output_text:\n",
    "                    continue\n",
    "                \n",
    "                f.write(json.dumps({'user': instruction, 'assistant': output_text}, ensure_ascii=False) + '\\n')\n",
    "                valid += 1\n",
    "                \n",
    "                if valid % 100_000 == 0:\n",
    "                    print(f'  ƒ∞≈ülendi: {valid:,}')\n",
    "        \n",
    "        # Drive'a da kaydet (tekrar indirme gerekmesin)\n",
    "        shutil.copy(SFT_PATH, SFT_PATH_DRIVE)\n",
    "        print(f'‚úÖ {valid:,} √∂rnek ‚Üí {SFT_PATH} (ve Drive\\'a kopyalandƒ±)')\n",
    "else:\n",
    "    import subprocess\n",
    "    lines = int(subprocess.check_output(['wc', '-l', SFT_PATH]).split()[0])\n",
    "    print(f'‚úÖ Dataset mevcut: ~{lines:,} satƒ±r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Script Ayarla: K√º√ß√ºk LR ve Doƒüru Dataset Yolu\n",
    "import re\n",
    "\n",
    "sft_script = '/content/Luna-LM/sft/train_sft.py'\n",
    "with open(sft_script, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Dataset path'ini deƒüi≈ütir\n",
    "content = content.replace(\n",
    "    '\"sft/sft_dataset.jsonl\"',\n",
    "    '\"sft/sft_continued_dataset.jsonl\"'\n",
    ")\n",
    "\n",
    "with open(sft_script, 'w', encoding='utf-8') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print('‚úÖ train_sft.py ‚Üí sft_continued_dataset.jsonl kullanacak ≈üekilde g√ºncellendi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Continued SFT Eƒüitimini Ba≈ülat\n",
    "# --checkpoint : √ñnceki SFT checkpoint\n",
    "# --lr 5e-6    : √áOK D√ú≈û√úK LR ‚Äî Catastrophic Forgetting'i √∂nler\n",
    "# --epochs 1   : 1.5M veri i√ßin 1 epoch yeterli\n",
    "# --batch_size 8 : H100 i√ßin g√ºvenli\n",
    "# --eval_freq 1000 : 1.5M veri i√ßin daha seyrek eval\n",
    "\n",
    "!python sft/train_sft.py \\\n",
    "    --checkpoint /content/Luna-LM/checkpoints/{PREV_SFT_NAME} \\\n",
    "    --lr 5e-6 \\\n",
    "    --epochs 1 \\\n",
    "    --batch_size 8 \\\n",
    "    --eval_freq 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. En Yeni Checkpoint'i Drive'a Kaydet\n",
    "import glob\n",
    "\n",
    "sft_dirs = sorted(glob.glob('/content/Luna-LM/checkpoints/sft_*'))\n",
    "if sft_dirs:\n",
    "    latest = sft_dirs[-1]\n",
    "    dest = os.path.join(DRIVE_DIR, os.path.basename(latest))\n",
    "    shutil.copytree(latest, dest, dirs_exist_ok=True)\n",
    "    print(f'‚úÖ Drive\\'a kaydedildi: {dest}')\n",
    "else:\n",
    "    print('‚ùå Checkpoint bulunamadƒ±!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Hƒ±zlƒ± Test\n",
    "import torch, glob\n",
    "from luna.utils import load_model\n",
    "from luna.generate import generate_text\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sft_dirs = sorted(glob.glob('/content/Luna-LM/checkpoints/sft_*'))\n",
    "model, tokenizer, _ = load_model(sft_dirs[-1], device)\n",
    "model.eval()\n",
    "\n",
    "def chat(q, temperature=0.3):\n",
    "    prompt = f'<system>Senin adƒ±n Luna. Yardƒ±msever bir asistansƒ±n.</system>\\n<user>{q}</user>\\n<assistant>'\n",
    "    out = generate_text(model, tokenizer, device, prompt,\n",
    "                        max_new_tokens=200, temperature=temperature,\n",
    "                        top_k=40, repetition_penalty=1.2)\n",
    "    # Normalize tags (tokenizer bo≈üluk ekleyebilir)\n",
    "    out = out.replace('< assistant >', '<assistant>').replace('< / assistant >', '</assistant>')\n",
    "    out = out.replace('< user >', '<user>').replace('< system >', '<system>')\n",
    "    \n",
    "    if '<assistant>' in out:\n",
    "        ans = out.split('<assistant>')[-1]\n",
    "        for stop in ['</assistant>', '<user>', '<system>', '[SEP]']:\n",
    "            ans = ans.split(stop)[0]\n",
    "        return ans.strip()\n",
    "    return out[-200:].strip()\n",
    "\n",
    "print('='*50)\n",
    "print('üåô LUNA-LARGE ‚Äî CONTINUED SFT TEST')\n",
    "print('='*50)\n",
    "\n",
    "for q in [\n",
    "    'T√ºrkiye\\'nin ba≈ükenti neresidir?',\n",
    "    'Yapay zeka nedir?',\n",
    "    'G√ºne≈ü hangi y√∂nden doƒüar?',\n",
    "    'Fotossentez nedir, kƒ±saca a√ßƒ±kla.',\n",
    "]:\n",
    "    print(f'\\n‚ùì {q}')\n",
    "    print(f'ü§ñ {chat(q)}')\n",
    "    print('-'*30)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "H100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
"

# TÃ¼rkÃ§e Tokenizer KullanÄ±m Rehberi

Bu dosyalar, Luna-LM projesinde TÃ¼rkÃ§e tokenizer kullanÄ±mÄ± iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### YÃ¶ntem 1: Pretrained Tokenizer (Ã–NERÄ°LEN - En HÄ±zlÄ±)

```bash
# Gerekli paketleri yÃ¼kle
pip install transformers tokenizers

# Test et
python turkish_tokenizer_pretrained.py
```

**ArtÄ±larÄ±:**
- âœ… HiÃ§ eÄŸitim gerektirmez
- âœ… AnÄ±nda kullanÄ±ma hazÄ±r
- âœ… 32K+ TÃ¼rkÃ§e vocab
- âœ… Profesyonel kalite

**Eksileri:**
- âŒ Foundation corpus'unuza Ã¶zel deÄŸil

---

### YÃ¶ntem 2: Hugging Face Tokenizers (Profesyonel)

```bash
# Tokenizer eÄŸit (5-10 dakika)
python turkish_tokenizer_huggingface.py

# Test et
python turkish_gpt_full_example.py
```

**ArtÄ±larÄ±:**
- âœ… Ã‡ok hÄ±zlÄ± (Rust tabanlÄ±)
- âœ… Corpus'unuza Ã¶zel
- âœ… EndÃ¼stri standardÄ±
- âœ… Kolay kullanÄ±m

**Eksileri:**
- âŒ Ek paket gerektirir: `tokenizers`

---

### YÃ¶ntem 3: SÄ±fÄ±rdan BPE (EÄŸitim AmaÃ§lÄ±)

```bash
# Tokenizer eÄŸit (yavaÅŸ olabilir)
python turkish_tokenizer_training.py

# DataLoader ile kullan
python turkish_gpt_dataloader.py

# Tam Ã¶rnek
python turkish_gpt_full_example.py
```

**ArtÄ±larÄ±:**
- âœ… BPE algoritmasÄ±nÄ± Ã¶ÄŸrenirsiniz
- âœ… Tamamen kontrol sizde
- âœ… Corpus'unuza Ã¶zel

**Eksileri:**
- âŒ YavaÅŸ (saf Python)
- âŒ KarmaÅŸÄ±k kod

---

## ğŸ“ Dosya AÃ§Ä±klamalarÄ±

| Dosya | AÃ§Ä±klama |
|-------|----------|
| `turkish_tokenizer_pretrained.py` | HazÄ±r TÃ¼rkÃ§e tokenizer kullanÄ±mÄ± |
| `turkish_tokenizer_huggingface.py` | HF Tokenizers ile eÄŸitim |
| `turkish_tokenizer_training.py` | SÄ±fÄ±rdan BPE implementasyonu |
| `turkish_gpt_dataloader.py` | Custom tokenizer + DataLoader |
| `turkish_gpt_full_example.py` | Tam GPT modeli Ã¶rneÄŸi |

---

## ğŸ¯ AdÄ±m AdÄ±m: Ä°lk Defa BaÅŸlayanlar

### 1. OrtamÄ± HazÄ±rla

```bash
# Proje dizinine git
cd Luna-LM

# Virtual environment aktif et (varsa)
# Windows:
venv\Scripts\activate

# Gerekli paketleri yÃ¼kle
pip install transformers tokenizers torch
```

### 2. Tokenizer SeÃ§ ve Test Et

**HÄ±zlÄ± Test (Ã–nerilen):**
```bash
python turkish_tokenizer_pretrained.py
```

**Custom EÄŸit:**
```bash
python turkish_tokenizer_huggingface.py
```

### 3. GPT ile Kullan

```bash
python turkish_gpt_full_example.py
```

---

## ğŸ”§ Mevcut KodlarÄ± Adapte Etme

### Eski Kod (GPT-2):
```python
import tiktoken

tokenizer = tiktoken.get_encoding("gpt2")
token_ids = tokenizer.encode(text)
```

### Yeni Kod (TÃ¼rkÃ§e - SeÃ§enek 1):
```python
from turkish_tokenizer_pretrained import PretrainedTurkishTokenizer

tokenizer = PretrainedTurkishTokenizer('dbmdz/bert-base-turkish-cased')
token_ids = tokenizer.encode(text)
```

### Yeni Kod (TÃ¼rkÃ§e - SeÃ§enek 2):
```python
from turkish_tokenizer_huggingface import HFTokenizerWrapper

tokenizer = HFTokenizerWrapper('turkish_hf_tokenizer.json')
token_ids = tokenizer.encode(text)
```

### Yeni Kod (TÃ¼rkÃ§e - SeÃ§enek 3):
```python
from turkish_gpt_dataloader import TurkishTokenizer

tokenizer = TurkishTokenizer('turkish_tokenizer.json')
token_ids = tokenizer.encode(text)
```

---

## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma

| Ã–zellik | Pretrained | Hugging Face | SÄ±fÄ±rdan BPE |
|---------|-----------|--------------|--------------|
| **HÄ±z** | âš¡âš¡âš¡ | âš¡âš¡âš¡ | âš¡ |
| **EÄŸitim SÃ¼resi** | 0 dk | 5-10 dk | 30-60 dk |
| **Corpus'a Ã–zel** | âŒ | âœ… | âœ… |
| **Vocab Size** | 32K | Ayarlanabilir | Ayarlanabilir |
| **KullanÄ±m KolaylÄ±ÄŸÄ±** | â­â­â­ | â­â­â­ | â­â­ |
| **EÄŸitim DeÄŸeri** | â­ | â­â­ | â­â­â­ |

---

## ğŸ› SÄ±k KarÅŸÄ±laÅŸÄ±lan Sorunlar

### 1. "ModuleNotFoundError: No module named 'transformers'"
```bash
pip install transformers
```

### 2. "ModuleNotFoundError: No module named 'tokenizers'"
```bash
pip install tokenizers
```

### 3. "FileNotFoundError: turkish_tokenizer.json"
```bash
# Ã–nce tokenizer'Ä± eÄŸitin:
python turkish_tokenizer_training.py
# veya
python turkish_tokenizer_huggingface.py
```

### 4. YavaÅŸ EÄŸitim
- `turkish_tokenizer_huggingface.py` kullanÄ±n (Ã§ok daha hÄ±zlÄ±)
- Veya corpus boyutunu azaltÄ±n (test iÃ§in)

---

## ğŸ’¡ Ã–neriler

1. **Ä°lk Kez BaÅŸlÄ±yorsanÄ±z:** `turkish_tokenizer_pretrained.py` ile baÅŸlayÄ±n
2. **Production Ä°Ã§in:** `turkish_tokenizer_huggingface.py` ile custom tokenizer eÄŸitin
3. **Ã–ÄŸrenme Ä°Ã§in:** `turkish_tokenizer_training.py` ile BPE algoritmasÄ±nÄ± anlayÄ±n

---

## ğŸ“š Ek Kaynaklar

- [BPE AlgoritmasÄ± AÃ§Ä±klamasÄ±](LLMs-from-scratch/ch02/05_bpe-from-scratch/)
- [Hugging Face Tokenizers Docs](https://huggingface.co/docs/tokenizers/)
- [TÃ¼rkÃ§e BERT Model](https://huggingface.co/dbmdz/bert-base-turkish-cased)

---

## âœ… BaÅŸarÄ± KontrolÃ¼

AÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rÄ±n:

```python
from turkish_tokenizer_pretrained import PretrainedTurkishTokenizer

tokenizer = PretrainedTurkishTokenizer('dbmdz/bert-base-turkish-cased')
text = "Merhaba dÃ¼nya! Yapay zekÃ¢ Ã§alÄ±ÅŸÄ±yorum."
encoded = tokenizer.encode(text)
decoded = tokenizer.decode(encoded)

print(f"Orijinal: {text}")
print(f"Encoded: {encoded}")
print(f"Decoded: {decoded}")
print("\nâœ… Tokenizer baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yor!")
```

EÄŸer hata almadÄ±ysanÄ±z, hazÄ±rsÄ±nÄ±z! ğŸ‰
